{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import bisect\n",
    "from collections import defaultdict\n",
    "\n",
    "from io import StringIO\n",
    "from math import ceil, log2\n",
    "\n",
    "\n",
    "###########################################################################################\n",
    "# Global variables\n",
    "pattern1 = 'ATGATG'\n",
    "pattern2 = 'CTCTCTA'\n",
    "pattern3 = 'TCACTACTCTCA'\n",
    "\n",
    "# Canis lupus familiaris genome, chromosome 1\n",
    "file_name1 = 'cfa_ref_CanFam3.1_chr1.fa'\n",
    "# Phoenix dactylifera genome\n",
    "file_name2 = '42345_ref_DPV01_chrUn.fa'\n",
    "# Ananascomosus genome, chromosome 1\n",
    "file_name3 = '4615_ref_ASM154086v1_chr1.fa'\n",
    "\n",
    "\n",
    "###########################################################################################\n",
    "# Sorted index\n",
    "class IndexSorted(object):\n",
    "\n",
    "    # Constructor\n",
    "    def __init__(self, name, text, length):\n",
    "        self.name = name  # short sequence name\n",
    "        self.text = text  # text to parse\n",
    "        self.length = length  # length of substrings - index entries\n",
    "        self.index = []  # list index\n",
    "\n",
    "        for i in range(len(text) - length + 1):\n",
    "            self.index.append((text[i:i + length], i))  # add <substr, offset> pair\n",
    "        self.index.sort()  # sort pairs\n",
    "\n",
    "    # Find possible pattern locations in index\n",
    "    def query(self, p):\n",
    "        st = bisect.bisect_left(self.index, (p[:self.length], -1))  # binary search\n",
    "        en = bisect.bisect_right(self.index, (p[:self.length], sys.maxsize))  # binary search\n",
    "        hits = self.index[st:en]  # this range of elements corresponds to the hits\n",
    "        return [h[1] for h in hits]  # return just the offsets\n",
    "\n",
    "\n",
    "###########################################################################################\n",
    "# Hash table\n",
    "class IndexHash(object):\n",
    "\n",
    "    # Constructor\n",
    "    def __init__(self, name, text, length):\n",
    "        self.name = name  # short sequence name\n",
    "        self.text = text  # text to parse\n",
    "        self.length = length  # length of substrings -index entries\n",
    "        self.index = {}  # dictionary index\n",
    "\n",
    "        # Populate the dictionary with substring : [location1, location2, ...] pairs\n",
    "        for i in range(len(text) - length + 1):\n",
    "            substr = text[i:i + length]\n",
    "            if substr in self.index:\n",
    "                self.index[substr].append(i)  # substring already in dictionary\n",
    "            else:\n",
    "                self.index[substr] = [i]  # add to dictionary\n",
    "\n",
    "    # Find possible pattern locations in dictionary\n",
    "    def query(self, pattern):\n",
    "        return self.index.get(pattern[:self.length], [])\n",
    "\n",
    "\n",
    "###########################################################################################\n",
    "# Suffix array\n",
    "class SuffixArray(object):\n",
    "\n",
    "    def sort_bucket(self, text, bucket, order):\n",
    "        d = defaultdict(list)\n",
    "        for i in bucket:\n",
    "            key = text[i:i + order]\n",
    "            d[key].append(i)\n",
    "        result = []\n",
    "        for k, v in sorted(d.items()):\n",
    "            if len(v) > 1:\n",
    "                result += self.sort_bucket(text, v, order * 2)\n",
    "            else:\n",
    "                result.append(v[0])\n",
    "        return result\n",
    "\n",
    "    def suffix_array(self):\n",
    "        return self.sort_bucket(self.text, (i for i in range(len(self.text))), 1)\n",
    "\n",
    "    def __init__(self, name, t):\n",
    "        self.name = name  # short sequence name\n",
    "        self.text = t\n",
    "        self.index = self.suffix_array()\n",
    "\n",
    "    def query(self, p):\n",
    "        first = 0\n",
    "        list = []\n",
    "        last = len(self.index) - 1\n",
    "        while first <= last:  # binary search\n",
    "            midpoint = (first + last) // 2\n",
    "            startIndex = self.index[midpoint]\n",
    "            #print(self.text[startIndex:startIndex+len(p)])\n",
    "            #print(\"startIndex: \" + str(startIndex) + \", len(p): \" + str(len(p)) + \" , len(self.text): \" + str(len(self.text)))\n",
    "            if (startIndex + len(p)) <= len(self.text) and p == self.text[startIndex:startIndex + len(\n",
    "                    p)]:  # search for matching first length(p) characters\n",
    "                #print(\"match midpoint: \" + str(midpoint))\n",
    "                list.append(self.index[midpoint])\n",
    "                j = midpoint - 1\n",
    "                while True:  # find all matching before found string\n",
    "                    if j < 0:\n",
    "                        break\n",
    "                    if (self.index[j] + len(p)) <= len(self.text) and p == self.text[self.index[j]:self.index[j] + len(p)]:\n",
    "                        #print(\"match j: \" + str(j))\n",
    "                        list.append(self.index[j])\n",
    "                        j = j - 1\n",
    "                    else:\n",
    "                        #print(\"break j: \" + str(j))\n",
    "                        break\n",
    "                k = midpoint + 1\n",
    "                while True:  # find all matching after found string\n",
    "                    if k >= len(self.index):\n",
    "                        break\n",
    "                    if (self.index[k] + len(p)) <= len(self.text) and p == self.text[self.index[k]:self.index[k] + len(p)]:\n",
    "                        #print(\"match k: \" + str(k))\n",
    "                        list.append(self.index[k])\n",
    "                        k = k + 1\n",
    "                    else:\n",
    "                        #print(\"break k: \" + str(k))\n",
    "                        break\n",
    "                return list\n",
    "            else:\n",
    "                if p < self.text[startIndex:startIndex + len(p)]:\n",
    "                    #print(\"no match midpoint: \" + str(midpoint) + \", first: \" + str(first) + \", last: \" + str(last))\n",
    "                    last = midpoint - 1\n",
    "                else:\n",
    "                    #print(\"no match midpoint: \" + str(midpoint) + \", first: \" + str(first) + \", last: \" + str(last))\n",
    "                    first = midpoint + 1\n",
    "        return list\n",
    "\n",
    "###########################################################################################\n",
    "# Suffix Tree\n",
    "class _SNode():\n",
    "    \"\"\"Class representing a Node in the Suffix tree.\"\"\"\n",
    "\n",
    "    def __init__(self, idx=-1, parentNode=None, depth=-1):\n",
    "        # Links\n",
    "        self._suffix_link = None\n",
    "        self.transition_links = []\n",
    "        # Properties\n",
    "        self.idx = idx\n",
    "        self.depth = depth\n",
    "        self.parent = parentNode\n",
    "        self.generalized_idxs = {}\n",
    "\n",
    "    def __str__(self):\n",
    "        return (\"SNode: idx:\" + str(self.idx) + \" depth:\" + str(self.depth) +\n",
    "                \" transitons:\" + str(self.transition_links))\n",
    "\n",
    "    def _add_suffix_link(self, snode):\n",
    "        self._suffix_link = snode\n",
    "\n",
    "    def _get_suffix_link(self):\n",
    "        if self._suffix_link != None:\n",
    "            return self._suffix_link\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def _get_transition_link(self, suffix):\n",
    "        for node, _suffix in self.transition_links:\n",
    "            if _suffix == '__@__' or suffix == _suffix:\n",
    "                return node\n",
    "        return False\n",
    "\n",
    "    def _add_transition_link(self, snode, suffix=''):\n",
    "        tl = self._get_transition_link(suffix)\n",
    "        if tl:  # TODO: imporve this.\n",
    "            self.transition_links.remove((tl, suffix))\n",
    "        self.transition_links.append((snode, suffix))\n",
    "\n",
    "    def _has_transition(self, suffix):\n",
    "        for node, _suffix in self.transition_links:\n",
    "            if _suffix == '__@__' or suffix == _suffix:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def is_leaf(self):\n",
    "        return self.transition_links == []\n",
    "\n",
    "    def _traverse(self, f):\n",
    "        for (node, _) in self.transition_links:\n",
    "            node._traverse(f)\n",
    "        f(self)\n",
    "\n",
    "    def _get_leaves(self):\n",
    "        if self.is_leaf():\n",
    "            return [self]\n",
    "        else:\n",
    "            return [x for (n, _) in self.transition_links for x in n._get_leaves()]\n",
    "\n",
    "\n",
    "class SuffixTree():\n",
    "    \"\"\"Class representing the suffix tree.\"\"\"\n",
    "\n",
    "    def __init__(self, name, input):\n",
    "        self.text = input\n",
    "        self.name = name\n",
    "        self.root = _SNode()\n",
    "        self.root.depth = 0\n",
    "        self.root.idx = 0\n",
    "        self.root.parent = self.root\n",
    "        self.root._add_suffix_link(self.root)\n",
    "\n",
    "        self.build(input)\n",
    "\n",
    "    def build(self, x):\n",
    "        x += '$'\n",
    "        \"\"\"Builds a Suffix tree.\n",
    "        Builds a Suffix tree using McCreight O(n) algorithm.\"\"\"\n",
    "        self.word = x\n",
    "        u = self.root\n",
    "        d = 0\n",
    "        for i in range(len(x)):\n",
    "            while u.depth == d and u._has_transition(x[d + i]):\n",
    "                u = u._get_transition_link(x[d + i])\n",
    "                d = d + 1\n",
    "                while d < u.depth and x[u.idx + d] == x[i + d]:\n",
    "                    d = d + 1\n",
    "            if d < u.depth:\n",
    "                u = self._create_node(x, u, d)\n",
    "            self._create_leaf(x, i, u, d)\n",
    "            if not u._get_suffix_link():\n",
    "                self._compute_slink(x, u)\n",
    "            u = u._get_suffix_link()\n",
    "            d = d - 1\n",
    "            if d < 0:\n",
    "                d = 0\n",
    "\n",
    "    def _create_node(self, x, u, d):\n",
    "        i = u.idx\n",
    "        p = u.parent\n",
    "        v = _SNode(idx=i, depth=d)\n",
    "        v._add_transition_link(u, x[i + d])\n",
    "        u.parent = v\n",
    "        p._add_transition_link(v, x[i + p.depth])\n",
    "        v.parent = p\n",
    "        return v\n",
    "\n",
    "    def _create_leaf(self, x, i, u, d):\n",
    "        w = _SNode()\n",
    "        w.idx = i\n",
    "        w.depth = len(x) - i\n",
    "        u._add_transition_link(w, x[i + d])\n",
    "        w.parent = u\n",
    "        return w\n",
    "\n",
    "    def _compute_slink(self, x, u):\n",
    "        d = u.depth\n",
    "        v = u.parent._get_suffix_link()\n",
    "        while v.depth < d - 1:\n",
    "            v = v._get_transition_link(x[u.idx + v.depth + 1])\n",
    "        if v.depth > d - 1:\n",
    "            v = self._create_node(x, v, d - 1)\n",
    "        u._add_suffix_link(v)\n",
    "\n",
    "    def query(self, y):\n",
    "        node = self.root\n",
    "        while True:\n",
    "            edge = self._edgeLabel(node, node.parent)\n",
    "            if edge.startswith(y):\n",
    "                break\n",
    "\n",
    "            i = 0\n",
    "            while (i < len(edge) and edge[i] == y[0]):\n",
    "                y = y[1:]\n",
    "                i += 1\n",
    "\n",
    "            if i != 0:\n",
    "                if i == len(edge) and y != '':\n",
    "                    pass\n",
    "                else:\n",
    "                    return []\n",
    "\n",
    "            node = node._get_transition_link(y[0])\n",
    "            if not node:\n",
    "                return []\n",
    "\n",
    "        leaves = node._get_leaves()\n",
    "        return [n.idx for n in leaves]\n",
    "\n",
    "    def _edgeLabel(self, node, parent):\n",
    "        \"\"\"Helper method, returns the edge label between a node and it's parent\"\"\"\n",
    "        return self.word[node.idx + parent.depth: node.idx + node.depth] \n",
    "\n",
    "\n",
    "###########################################################################################\n",
    "# Utility function for parsing input FASTA files\n",
    "# Returns dictionary with sequence_name : base_string pairs\n",
    "def parse_fasta(fh):\n",
    "    fa = {}\n",
    "    current_short_name = None\n",
    "    # Part 1: compile list of lines per sequence\n",
    "    for ln in fh:\n",
    "        if ln[0] == '>':\n",
    "            # new name line; remember current sequence's short name\n",
    "            long_name = ln[1:].rstrip()\n",
    "            current_short_name = long_name.split()[0]\n",
    "            fa[current_short_name] = []\n",
    "        else:\n",
    "            # append nucleotides to current sequence\n",
    "            if (current_short_name != None):\n",
    "                fa[current_short_name].append(ln.rstrip())\n",
    "    # Part 2: join lists into strings\n",
    "    for short_name, nuc_list in fa.items():\n",
    "        # join this sequence's lines into one long string\n",
    "        fa[short_name] = ''.join(nuc_list)\n",
    "    return fa\n",
    "\n",
    "\n",
    "###########################################################################################\n",
    "# Pass through all possible alignments and leave only real ones\n",
    "def filter_real_alignments(pattern, possible_alignments, text):\n",
    "    real_alignments = []\n",
    "    for i in possible_alignments:\n",
    "        #print(\"text[\" + str(i) + \":\" + str(i+len(pattern)) + \"]\")\n",
    "        if pattern == text[i:i + len(pattern)]:\n",
    "            real_alignments.append(i)\n",
    "    return real_alignments\n",
    "\n",
    "\n",
    "###########################################################################################\n",
    "# Choose string matching algorithm\n",
    "def choose_algorithm():\n",
    "    global choice\n",
    "    global structure_name\n",
    "    \n",
    "    print('Exact String Matching Algorithms\\n')\n",
    "    print('Choose algorithm:')\n",
    "    print('1. Sorted Index')\n",
    "    print('2. Hash Table')\n",
    "    print('3. Suffix Array')\n",
    "    print('4. Suffix Tree')\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            choice = int(input())\n",
    "            if (choice < 1 or choice > 4):\n",
    "                raise ValueError\n",
    "            \n",
    "            if (choice == 1):\n",
    "                structure_name = 'Sorted Index'\n",
    "            elif (choice == 2):\n",
    "                structure_name = 'Hash Table'\n",
    "            elif (choice == 3):\n",
    "                structure_name = 'Suffix Array'\n",
    "            else:\n",
    "                structure_name = 'Suffix Tree'\n",
    "                return\n",
    "\n",
    "            print('\\nYou chose the ' + structure_name + ' algorithm.')\n",
    "\n",
    "            return choice\n",
    "        except ValueError:\n",
    "            print('***ERROR***\\n', 'Enter a valid number between 1 and 4:')\n",
    "\n",
    "\n",
    "###########################################################################################\n",
    "# Open file, create sequence dictionaries\n",
    "def prepare_file(file_name):\n",
    "    global parsed_fasta\n",
    "    global file\n",
    "\n",
    "    print('\\nPreparing file ' + file_name + '...')\n",
    "    file = open(file_name, 'r')\n",
    "    text = file.read()\n",
    "    string_io = StringIO(text)\n",
    "    parsed_fasta = parse_fasta(string_io)\n",
    "    print('Prepared!')\n",
    "\n",
    "\n",
    "###########################################################################################\n",
    "# Create adequate data structure, based on the chosen algorithm\n",
    "def init_structure(name, text, length):\n",
    "    if (choice == 1):\n",
    "        return IndexSorted(name, text, length)\n",
    "    elif (choice == 2):\n",
    "        return IndexHash(name, text, length)\n",
    "    elif (choice == 3):\n",
    "        return SuffixArray(name, text)\n",
    "    elif (choice == 4):\n",
    "        return SuffixTree(name, text)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "###########################################################################################\n",
    "# Do all the needed processing for one file and given pattern\n",
    "def per_pattern_processing(pattern):\n",
    "    pattern_align_count = 0\n",
    "\n",
    "    print('\\nPattern ' + pattern)\n",
    "\n",
    "    # Query each sequence\n",
    "    for index in indexes:\n",
    "        # Query table for possible alignment positions\n",
    "        possible_alignments = index.query(pattern)\n",
    "\n",
    "        # Find real alignment positions\n",
    "        real_alignments = filter_real_alignments(pattern, possible_alignments, index.text)\n",
    "\n",
    "        #print('[sequence: ' + index.name + ', pattern: ' + pattern + '], number of alignment positions: ' + str(\n",
    "        #    len(real_alignments)))\n",
    "        pattern_align_count += len(real_alignments)\n",
    "\n",
    "    print('\\nPattern ' + pattern + ' alignments in all sequences: ' + str(pattern_align_count))\n",
    "\n",
    "\n",
    "###########################################################################################\n",
    "# Create one data structure for each sequence\n",
    "def create_indexes():\n",
    "    # Array of index structures for each sequence in file\n",
    "    global indexes\n",
    "    indexes = []\n",
    "    for key, value in parsed_fasta.items():\n",
    "        #print('Creating ' + structure_name + ' for sequence ' + key)\n",
    "        indexes.append(init_structure(key, value, 5))\n",
    "\n",
    "\n",
    "###########################################################################################\n",
    "# Do all the needed processing for one given file and three different patterns\n",
    "def file_processing(file_name):\n",
    "    prepare_file(file_name)\n",
    "\n",
    "    create_indexes()\n",
    "\n",
    "    per_pattern_processing(pattern1)\n",
    "    per_pattern_processing(pattern2)\n",
    "    per_pattern_processing(pattern3)\n",
    "\n",
    "    file.close()\n",
    "\n",
    "\n",
    "###########################################################################################\n",
    "# Main function\n",
    "def main():\n",
    "\n",
    "    choose_algorithm()\n",
    "\n",
    "    #file_processing(file_name1)\n",
    "\n",
    "    #file_processing(file_name2)\n",
    "\n",
    "    file_processing(file_name3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter_real_alignments\n",
    "pattern = \"ATC\"\n",
    "possible_alignments = [0, 8, 9, 10]\n",
    "text = \"ACGTGCTGAAAT\"\n",
    "real_alignments = filter_real_alignments(pattern, possible_alignments, text)\n",
    "assert real_alignments == []\n",
    "\n",
    "text = \"ATCTGCTGAAAT\"\n",
    "real_alignments = filter_real_alignments(pattern, possible_alignments, text)\n",
    "assert real_alignments == [0]\n",
    "\n",
    "pattern = \"ATC\"\n",
    "possible_alignments = [0, 3, 6, 9]\n",
    "text = \"ATCATCACTATC\"\n",
    "real_alignments = filter_real_alignments(pattern, possible_alignments, text)\n",
    "\n",
    "assert real_alignments == [0, 3, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse_fasta\n",
    "string_io = StringIO(\"\")\n",
    "parsed_fasta = parse_fasta(string_io)\n",
    "assert parsed_fasta == {}\n",
    "\n",
    "string_io = StringIO(\"sequence\")\n",
    "parsed_fasta = parse_fasta(string_io)\n",
    "assert parsed_fasta == {}\n",
    "\n",
    "string_io = StringIO(\">sequence\")\n",
    "parsed_fasta = parse_fasta(string_io)\n",
    "assert parsed_fasta[\"sequence\"] == \"\"\n",
    "\n",
    "string_io = StringIO(\">sequence\\nACTG\")\n",
    "parsed_fasta = parse_fasta(string_io)\n",
    "assert parsed_fasta[\"sequence\"] == \"ACTG\"\n",
    "\n",
    "string_io = StringIO(\">sequence\\nACTG\")\n",
    "parsed_fasta = parse_fasta(string_io)\n",
    "assert parsed_fasta[\"sequence\"] == \"ACTG\"\n",
    "\n",
    "string_io = StringIO(\">sequence1\\nACTG\\n>sequence2\\nCTGA\")\n",
    "parsed_fasta = parse_fasta(string_io)\n",
    "assert parsed_fasta[\"sequence1\"] == \"ACTG\"\n",
    "assert parsed_fasta[\"sequence2\"] == \"CTGA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact String Matching Algorithms\n",
      "\n",
      "Choose algorithm:\n",
      "1. Sorted Index\n",
      "2. Hash Table\n",
      "3. Suffix Array\n",
      "4. Suffix Tree\n",
      "1\n",
      "\n",
      "You chose the Sorted Index algorithm.\n"
     ]
    }
   ],
   "source": [
    "# choose_algorithm\n",
    "# redundant, already tested in function\n",
    "choice = choose_algorithm()\n",
    "assert (choice >= 1 and choice <= 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init_structure\n",
    "# check created structure type\n",
    "choice = 1\n",
    "struct = init_structure('...', 'SOME TEXT', 5)\n",
    "assert type(struct) is IndexSorted\n",
    "\n",
    "choice = 2\n",
    "struct = init_structure('...', 'SOME TEXT', 5)\n",
    "assert type(struct) is IndexHash\n",
    "\n",
    "choice = 3\n",
    "struct = init_structure('...', 'SOME TEXT', 5)\n",
    "assert type(struct) is SuffixArray\n",
    "\n",
    "choice = 4\n",
    "struct = init_structure('...', 'SOME TEXT', 5)\n",
    "assert type(struct) is SuffixTree\n",
    "\n",
    "choice = 5\n",
    "struct = init_structure('...', 'SOME TEXT', 5)\n",
    "assert type(struct) is type(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_indexes\n",
    "choice = 1\n",
    "\n",
    "string_io = StringIO(\"\")\n",
    "parsed_fasta = parse_fasta(string_io)\n",
    "create_indexes()\n",
    "assert len(indexes) == 0\n",
    "\n",
    "string_io = StringIO(\">sequence\")\n",
    "parsed_fasta = parse_fasta(string_io)\n",
    "create_indexes()\n",
    "assert len(indexes) == 1\n",
    "\n",
    "string_io = StringIO(\">sequence1\\nACTG\\n>sequence2\\nCTGA\")\n",
    "parsed_fasta = parse_fasta(string_io)\n",
    "create_indexes()\n",
    "assert len(indexes) == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SortedIndex query\n",
    "choice = 1\n",
    "string_io = StringIO(\">sequence\\nACGTAACTGTAACGGTAC\")\n",
    "parsed_fasta = parse_fasta(string_io)\n",
    "create_indexes()\n",
    "assert len(indexes[0].query(\"A\")) == 0 # query doesn't work for strings smaller than five characters\n",
    "assert len(indexes[0].query(\"ACGTA\")) == 1\n",
    "assert len(indexes[0].query(\"GTAACTG\")) == 2 # potentially two times, but really only once\n",
    "assert len(indexes[0].query(\"ACGTAACTGTAACGGTAC\")) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "choice = 2\n",
    "string_io = StringIO(\">sequence\\nACGTAACTGTAACGGTAC\")\n",
    "parsed_fasta = parse_fasta(string_io)\n",
    "create_indexes()\n",
    "assert len(indexes[0].query(\"A\")) == 0 # query doesn't work for strings smaller than five characters\n",
    "assert len(indexes[0].query(\"ACGTA\")) == 1\n",
    "assert len(indexes[0].query(\"GTAACTG\")) == 2 # potentially two times, but really only once\n",
    "assert len(indexes[0].query(\"ACGTAACTGTAACGGTAC\")) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "choice = 3\n",
    "string_io = StringIO(\">sequence\\nACGTAACTGTAACGGTCA\")\n",
    "parsed_fasta = parse_fasta(string_io)\n",
    "create_indexes()\n",
    "assert len(indexes[0].query(\"A\")) == 6\n",
    "assert len(indexes[0].query(\"AA\")) == 2\n",
    "assert len(indexes[0].query(\"ACGTA\")) == 1\n",
    "assert len(indexes[0].query(\"GTAACTG\")) == 1\n",
    "assert len(indexes[0].query(\"ACGTAACTGTAACGGTCA\")) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "choice = 4\n",
    "string_io = StringIO(\">sequence\\nACGTAACTGTAACGGTAC\")\n",
    "parsed_fasta = parse_fasta(string_io)\n",
    "create_indexes()\n",
    "assert len(indexes[0].query(\"A\")) == 6\n",
    "assert len(indexes[0].query(\"AA\")) == 2\n",
    "assert len(indexes[0].query(\"ACGTA\")) == 1\n",
    "assert len(indexes[0].query(\"GTAACTG\")) == 1\n",
    "assert len(indexes[0].query(\"ACGTAACTGTAACGGTAC\")) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some functions just encapsulate other function calls\n",
    "# main\n",
    "# file_processing\n",
    "# per_pattern_processing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
